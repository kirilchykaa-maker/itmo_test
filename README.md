Парсинг реализован инструментами автотестирования через playwright (поднимается headless браузер, нажимается кнопка скачать)

Скачанный pdf-файл конвертируется в xml и txt формат. На текущий момент в силу экономии токенов, активно используется только TXT, но стоит заметить, что LLM крайне хорошо показывают себя в случае ввода с явными семантическими якорями (из-за чего XML формат отлично подходит для промптинга), и в случае используемой в данном решении модели (Gemini FLASH) из-за его огромного контекстного окна, можно было бы и явно использовать XML-формат учебного плана.

В целом, необходимость экономить на токенах, следует из того, что учебный план кладется полностью в контекст на текущий момент, и если при 1-2 программах это еще не является проблемой, то при масштабировании ей станет. В таком случае, хорошим решением будет определять заранее (также средствами NLP) к какой программе относится вопрос, и класть в контекст только её учебный план. В RAG необходимости на данный момент не вижу, если оставаться даже в рамках класть полностью в контекст один учебный план, то качество ответов останется лучше из-за более полного контекста, а до лимита мы будем еще далеко, так как один учебный план не особо большой. Непонятно, актуально ли это в случае, например, бакалавриата или специалитета, так как там ожидается больший объем данных, и возможно пригодится RAG с чанкованием по структуре XML.

При решении задачи пользовался Cursor + Supercode.sh + Memory Bank. Изначально обсудил с моделью план действий, возможные подводные камни, затем итеративно реализовывали.